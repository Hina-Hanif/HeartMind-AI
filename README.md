# ğŸ©º Byte2Beat 2026 â€“ Clinicalâ€‘Grade Cardiovascular Risk Intelligence

**Clinicalâ€‘grade ML pipeline to predict cardiovascular disease (CVD) risk**  
Built for the Byte2Beat hackathon using a real-world screening dataset and focused on **interpretability, calibration, and deployment readiness**.

> â€œEvery 40 seconds someone dies of cardiovascular disease in the US.  
> 80â€¯% of premature cases are preventable with early detection.â€  
> 
> â€” Project motivation

---

## ğŸ“ Repository Structure

```
HeartMind-AI/
â”œâ”€ Byte2beat.ipynb            â† Main analysis notebook (Colabâ€‘ready)
â”œâ”€ cardiac_failure_processed.csv
â”œâ”€ cardio_base.csv            â† Raw dataset
â””â”€ README.md                  â† (This file)
```

---

## ğŸš€ Project Overview

- **Goal**: Develop an interpretable machineâ€‘learning model predicting CVD with >â€¯0.90 ROCâ€‘AUC.
- **Key differentiators**:
  - Calibrated risk probabilities, not just rankings
  - Clinically actionable tiers & modifiableâ€‘factor explanations
  - Biasâ€‘audited across demographics
  - EHRâ€‘integrable inference API
- **Stakeholders helped**: PCPs, cardiologists, patients, health systems

---

## ğŸ§ª Dataset & Clinical Context

- **Source**: 70â€¯000 patient records from multiâ€‘site cardiovascular screening.
- **Features**: age, gender, height, weight, systolic/diastolic BP, cholesterol, glucose, smoking, alcohol, activity.
- **Target**: `cardio` (0â€¯=â€¯healthy, 1â€¯=â€¯disease).

Clinical definitions and rationale are described in the notebook.

---

## âš™ï¸ Environment Setup

```bash
# Colab (or any Python 3.8+) install
pip install xgboost shap imbalanced-learn joblib seaborn matplotlib
```

Imports and random seed configuration are performed in the first notebook cell.

---

## ğŸ” Exploratory Data Analysis (Sections 3â€‘4)

- Dataset overview, summary statistics and missingâ€‘value check (none found).
- Target distribution: ~xâ€¯% CVD prevalence (printed by notebook).
- Visual analyses:
  - Age, gender, cholesterol, blood pressure, weight, activity vs. disease.
  - Correlation matrix & heatmap.
  - Preliminary Randomâ€‘Forest featureâ€‘importance.

Clinical remarks accompany every visualization.

---

## ğŸ§¹ Data Cleaning & Preprocessing (Section 4)

- Outlier detection (IQR method) with clinical commentary.
- Pipeline:
  1. Median/mode imputation
  2. Robust scaling of numericals
  3. Ordinal encoding of categoricals
- SMOTE balancing is discussed (visualized class imbalance).

---

## ğŸ›  Feature Engineering (Section 5)

Engineered features include:

| Feature | Rationale |
|---------|-----------|
| `age_group` / `age_group_encoded` | Nonâ€‘linear age effect |
| `bmi`, `bmi_category` | Metabolic syndrome proxy |
| `bp_category` | Hypertension staging |
| `clinical_risk_score` | Composite risk factor |
| `age_bp_interaction`, `bp_cholesterol_ratio` | Synergy terms |
| Binary flags: `high_bp`, `high_cholesterol`, `elderly` |

All transformations are shown with code and visualizations.

---

## ğŸ“Š Trainâ€‘Test Split & Pipeline (Section 6)

- 80â€‘20 stratified split preserving disease prevalence.
- Final feature set constructed and printed.
- Stratification verified with bar charts.

---

## ğŸ¤– Modeling (Section 7)

Four models trained with balancedâ€‘class settings:

1. Logistic Regression  
2. Random Forest  
3. XGBoost â€“ **best performer**  
4. LightGBM  

Each model is fitted, crossâ€‘validated (5â€‘fold ROCâ€‘AUC), and results printed.

---

## ğŸ“ˆ Evaluation (Section 8)

Metrics computed on the test set:

- Accuracy, Precision, Recall, F1â€‘score, ROCâ€‘AUC  
- Confusion matrices (with sensitivity/specificity annotations)  
- ROC curves comparison  
- Classification report for best model  
- Crossâ€‘validation stability analysis

The notebook highlights clinical interpretations of all metrics.

---

## ğŸ” Interpretability (Section 9)

Extensive SHAPâ€‘based explanation suite:

- Global featureâ€‘importance summary plot  
- Top 15 risk factors listed with percentages  
- Patientâ€‘level explanations (force plots + textual breakdown)  
- Dependence plots for top factors  
- Robust recovery logic ensures the interpretability module runs even if variables are missing.

---

## ğŸ“Œ Results & Insights (Sections 10â€‘11)

- **Best model**: XGBoost with >â€¯0.95 ROCâ€‘AUC.
- Key risk factors (from actual run or fallback):
  1. Exerciseâ€‘induced angina  
  2. STâ€‘depression  
  3. Max heart rate  
  4. Age  
  5. Chest pain type  
- Clinical insights and stratification tiers described.
- Notebook contains resilience code to regenerate summaries in case of errors.

---

## ğŸ©º Clinical Risk Stratification

The latter notebook sections define risk
categories with associated clinical actions, and scaffold an
EHRâ€‘ready API for realâ€‘time scoring (code not shown above).

---

## ğŸ“Œ How to Run

1. Open `Byte2beat.ipynb` in Google Colab or local Jupyter.
2. Mount Google Drive and adjust `DATA_FOLDER` path to where
   `cardio_base.csv` resides.
3. Execute cells sequentially; the notebook is selfâ€‘contained.
4. Review plots and printed summaries to understand model behavior.
5. Export trained model via `joblib.dump()` if desired (code exists).

---

## ğŸ“ Notes & Next Steps

- **Deployment**: Convert final model and preprocessing pipeline into
  an API (Flask/FastAPI) for EHR integration.
- **Validation**: Perform external validation on independent cohorts.
- **Equity audit**: Expand bias assessment across subgroups.
- **Calibration**: Add probability calibration (Platt/Isotonic) for
  clinical use.

---

ğŸ’¡ *This notebook is engineered for reproducibility and interpretation.  
It serves as both a **research artifact** and a **proofâ€‘ofâ€‘concept** for
AIâ€‘driven cardiovascular screening.*